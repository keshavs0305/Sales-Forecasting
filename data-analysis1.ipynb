import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import preprocessing
from sklearn.metrics import mean_squared_error
import xgboost as xgb
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import GridSearchCV
import warnings
warnings.filterwarnings("ignore")

xls = pd.ExcelFile('2 years data before 29-09-2021.xlsm',engine='openpyxl')
df1 = pd.read_excel(xls, '2 years data before 29-09-2021')
df2 = pd.read_excel(xls, 'Price increase dates')
df3 = pd.read_excel(xls, 'Mandatory vacation dates',names=['start','end'])

df1 = df1.iloc[:245815]
df2.dropna(axis=1,inplace=True)
df3.dropna(inplace=True)
df3.drop([0],inplace=True)
df1.drop(['Order nÂº','Custumer Name','Item Name','Subgroup_description'],axis=1,inplace=True)
df2.drop(['Subgroup of products (description)'],axis=1,inplace=True)

le = preprocessing.LabelEncoder()
for col in ['Country','State','City']:
    df1[col] = le.fit_transform(df1[[col]])
df = df1.groupby(['Order date','Custumer Id','Item Id','Country','State','City','Subgruop_ID']).mean().reset_index()"

"## recency, frequency, next_buy\n",
"### price_increase_30, is_vacation, vacation_30"

def time_series_bin(right,col):\n",

    ret = pd.DataFrame(pd.date_range(df['Order date'].min(),df['Order date'].max(),freq='d'),columns=['Date'])\n",
    try:\n",
        new_data = pd.merge(ret,right,left_on='Date',right_on=col,how='outer')\n",
    except:\n",
        new_data = pd.concat(ret,right,axis=1,join=\"outer\",)\n",
    new_data['ret']= new_data[col].isna()==0\n",
    new_data['ret'].replace({True:1,False:0},inplace=True)\n",
    return new_data['ret']"

def recency(dfr,cusid):\n",
    t_ = time_series_bin(dfr.loc[dfr['Custumer Id']==cusid][['Order date']].drop_duplicates(),'Order date')\n",
    t = np.where(t_.to_numpy()==1)[0]\n",
    t1 = [t[i]-t[i+1] for i in range(len(t)-1)]\n",
    tt = [0-t[0]]\n",
    [tt.append(i) for i in t1]\n",
    tt.append(t[-1]-len(t_))\n",

    data = []\n",
    for rec in tt :\n",
        [data.append(_) for _ in range(abs(rec))]\n",

    return data"

def buy_freq(dfr,cusid):\n",
    t = time_series_bin(dfr.loc[dfr['Custumer Id']==cusid][['Order date']].drop_duplicates(),'Order date')\n",
    ret = [0]\n",
    [ret.append(t[:i+1].mean()) for i in range(len(t)-1)]\n",

    return ret"

def price_inc_30(df,df2):\n",
    df2 = pd.read_excel(xls, 'Price increase dates')\n",
    df2.dropna(axis=1,inplace=True)\n",
    df2.drop(['Subgroup of products (description)'],axis=1,inplace=True)\n",
    df2 = pd.concat([df2[['Date of price increase']]\n",
                     ,pd.DataFrame.sparse.from_spmatrix((OneHotEncoder().fit_transform(df2.drop(['Date of price increase']\n",
                                                                                                ,axis=1))))\n",

                    ,axis=1)\n",
    df2 = df2.groupby(['Date of price increase']).sum()\n",

    x = pd.DataFrame(index=pd.date_range(df['Order date'].min(),df['Order date'].max(),freq='d'))\n",
    x = pd.concat([x,df2],join=\"outer\",axis=1,)\n",
    x.fillna(0,inplace=True)\n",
    x.reset_index().drop(['index'],axis=1,inplace=True)\n",

    return x"

def check_next_n(dfp,n):\n",
    for col in dfp.columns:\n",
        x = np.where(dfp[col].to_numpy()==1)\n",
        x = x[0]\n",
        ar = [0 for _ in range(x[0]-n)]\n",
        for i in range(1,n+1):\n",
            ar.append(i)\n",
        for i in range(x[1]-x[0]-n):\n",
            ar.append(0)\n",
        for i in range(1,n+1):\n",
            ar.append(i)\n",
        for i in range(x[2]-x[1]-n):\n",
            ar.append(0)\n",
        for i in range(1,n+1):\n",
            ar.append(i)\n",
        for i in range(len(dfp[col])-len(ar)):\n",
            ar.append(0)\n",
        dfp[col] = ar\n",
    return dfp"

def next_buy(dfr,cusid):\n",
    t_ = time_series_bin(dfr.loc[dfr['Custumer Id']==cusid][['Order date']].drop_duplicates(),'Order date')\n",
    t = np.where(t_.to_numpy()==1)[0]\n",
    t1 = [t[i+1]-t[i] for i in range(len(t)-1)]\n",
    t2 = []\n",
    tt = [t[0]]\n",
    [tt.append(i) for i in t1]\n",
    tt.append(len(t_)-t[-1])\n",

    for i in range(len(tt)-1):\n",
        for j in range(tt[i]):\n",
            t2.append(tt[i]-j-1)\n",

    x = len(t_)-len(t2)\n",
    for i in range(len(t_)-len(t2)):\n",
        t2.append(90)\n",
    return(t2,x)"

def data_cus(df1,df2,cusid):\n",
    ret = pd.DataFrame()\n",
    ret['recency'] = recency(df1,cusid)\n",

    ret['buy_freq'] = buy_freq(df1,cusid)\n",
    dft = check_next_n(price_inc_30(df1,df2),30)\n",
    for col in dft.columns:\n",
        ret['price_inc_'+str(col)] = list(dft[col])\n",
    a,b = next_buy(df1,cusid)\n",

    ret['next_buy'],n = next_buy(df1,cusid)\n",

    return ret,n"

def new_data(cusid):\n",
    t,n = data_cus(df,df2,cusid)\n",
    recency = t.recency.values[-1]+1\n",
    buy_freq = t.buy_freq.values[-1]*len(t)/(len(t)+1)\n",
    return([recency, buy_freq] + [0 for _ in range(10)] + [0])"

def preds(cusid):\n",
    scale = StandardScaler()\n",
    data,n = data_cus(df,df2,cusid)\n",
    data = scale.fit_transform(data.head(len(data)-n))\n",

    #train, test = data[:round(len(data)*0.8)], data[round(len(data)*0.8):]\n",
    #x_train, x_test, y_train, y_test = train[:,:-1], test[:,:-1], train[:,-1], test[:,-1]\n",

    #model = SVR().fit(x_train, y_train)\n",
    #r1 = model.score(x_test, y_test)\n",
    #r2 = mean_squared_error(model.predict(x_test),y_test)\n",

#     pred = [np.append(x_test[i,:],model.predict(x_test[i,:].reshape(1,-1))) for i in range(len(x_test))]\n",
#     true = [np.append(x_test[i,:],y_test[i].reshape(1,-1)) for i in range(len(x_test))]\n",
#     plt.plot(scale.inverse_transform(pred)[:,-1],label='preds')\n",
#     plt.plot(scale.inverse_transform(true)[:,-1])\n",
#     plt.legend()\n",
#     plt.show()\n",

    model = SVR().fit(data[:,:-1],data[:,-1])\n",
    data,n = data_cus(df,df2,cusid)\n",
    pred = model.predict(scale.transform(data)[-1][:-1].reshape(1, -1))\n",

    r3 = scale.inverse_transform([0 for _ in range(12)] + [pred[0]])[-1]\n",

    return r3"

pred = {'cusid':[],'pred':[]}\n",
for id_ in df['Custumer Id'].unique():\n",
    if id_ in [903]:\n",
        pred['cusid'].append(id_)\n",
        pred['pred'].append(np.nan)\n",
        continue\n",
    pred['cusid'].append(id_)\n",
    pred['pred'].append(preds(id_))\n",
#pred\n",
#pd.DataFrame(pred).to_csv('sample.csv',index=False)"

d = pd.DataFrame(pred)\n",
d.loc[d['cusid']==887]"

pd.DataFrame(pred).to_csv('sample.csv',index=False)"

def preds(cusid):\n",
    scale = StandardScaler()\n",
    data,n = data_cus(df,df2,cusid)\n",
    data = scale.fit_transform(data.head(len(data)-n))\n",

    #train, test = data[:round(len(data)*0.8)], data[round(len(data)*0.8):]\n",
    #x_train, x_test, y_train, y_test = train[:,:-1], test[:,:-1], train[:,-1], test[:,-1]\n",

    #model = SVR().fit(x_train, y_train)\n",
    #r1 = model.score(x_test, y_test)\n",
    #r2 = mean_squared_error(model.predict(x_test),y_test)\n",

#     pred = [np.append(x_test[i,:],model.predict(x_test[i,:].reshape(1,-1))) for i in range(len(x_test))]\n",
#     true = [np.append(x_test[i,:],y_test[i].reshape(1,-1)) for i in range(len(x_test))]\n",
#     plt.plot(scale.inverse_transform(pred)[:,-1],label='preds')\n",
#     plt.plot(scale.inverse_transform(true)[:,-1])\n",
#     plt.legend()\n",
#     plt.show()\n",

    #model = SVR().fit(data[:,:-1],data[:,-1])\n",
    model = xgb.XGBRegressor().fit(data[:,:-1],data[:,-1])\n",
    data,n = data_cus(df,df2,cusid)\n",
    pred = model.predict(scale.transform(data)[-1][:-1].reshape(1, -1))\n",

    r3 = scale.inverse_transform([0 for _ in range(12)] + [pred[0]])[-1]\n",

    return r3"

scale = StandardScaler()\n",
data,n = data_cus(df,df2,887)\n",
data = scale.fit_transform(data.head(n))\n",

train, test = data[:round(len(data)*0.6)], data[round(len(data)*0.6):]\n",
x_train, x_test, y_train, y_test = train[:,:-1], test[:,:-1], train[:,-1], test[:,-1]"

xgb_ = xgb.XGBRegressor()\n",
xgb_.fit(x_train,y_train)"

xgb_.score(x_test,y_test)"

plt.plot(xgb_.predict(x_test),label='preds')\n",
plt.plot(y_test)\n",
plt.legends()\n",

model = SVR().fit(x_train, y_train)\n",
r1 = model.score(x_test, y_test)\n",
r2 = mean_squared_error(model.predict(x_test),y_test)"

r1,r2"


plt.plot(model.predict(x_test),label='preds')\n",
plt.plot(y_test)\n",
plt.legends\n",
plt.show()